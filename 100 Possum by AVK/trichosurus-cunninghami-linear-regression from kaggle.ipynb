{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-25T00:23:42.278818Z","iopub.execute_input":"2022-04-25T00:23:42.279159Z","iopub.status.idle":"2022-04-25T00:23:42.296676Z","shell.execute_reply.started":"2022-04-25T00:23:42.2791Z","shell.execute_reply":"2022-04-25T00:23:42.295569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2022-04-25T00:23:42.302022Z","iopub.execute_input":"2022-04-25T00:23:42.302519Z","iopub.status.idle":"2022-04-25T00:23:42.762353Z","shell.execute_reply.started":"2022-04-25T00:23:42.302477Z","shell.execute_reply":"2022-04-25T00:23:42.761647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This dataset is made by morphometric measurements of ","metadata":{}},{"cell_type":"markdown","source":"This dataset is made by morphometric measurements of Trichosurus caninus, a marsupial endemic to Australia. The dataset contains data from 104 individuals, which are the following.\n\nTrapping Site: 1 (Cambarville, next to Melbourne) to 7 (Allyn River Forest Park, next to Sidney)\nPopulation: Vic (Victoria) or Other (New South Wales or Queensland)\nGender: m (male), f (female)\nHead length: The distance from the tip of the nose to the external occipital protuberance\nSkull width: The distance across the widest part of the head (immediately in front of the\nears)\nTotal body length: The length of the body measured from the tip of the nose along the head and\nspine to the tip of the uncurled tail\nTail length: The distance from the base of the tail to the tip of the tail\nPes length: The distance from the heel to the tip of the largest toe (excluding the claw)\nLength of the ear conch: The distance from the notch at the base of the pinna to the highest point of the pinna\nEye size: The distance between the medial canthus and lateral canthus of the right eye\nChest girth: The body girth measured immediately behind the forelimbs\nBelly girth: The body girth measured immediately behind the caudal rib\n\nIn this notebook, as an exercise in Multiple Linear Regression, we are going to predict Total Body Length based on the other informations.","metadata":{}},{"cell_type":"code","source":"#Let's open the data and take a look.\ndf = pd.read_csv(\"/kaggle/input/openintro-possum/possum.csv\")\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-25T00:23:42.763744Z","iopub.execute_input":"2022-04-25T00:23:42.764226Z","iopub.status.idle":"2022-04-25T00:23:42.797997Z","shell.execute_reply.started":"2022-04-25T00:23:42.764183Z","shell.execute_reply":"2022-04-25T00:23:42.797158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"execution":{"iopub.status.busy":"2022-04-25T00:23:42.800799Z","iopub.execute_input":"2022-04-25T00:23:42.801283Z","iopub.status.idle":"2022-04-25T00:23:42.847849Z","shell.execute_reply.started":"2022-04-25T00:23:42.801239Z","shell.execute_reply":"2022-04-25T00:23:42.846935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are two individuals whose age was not registered and one individual without foot length registered, let's exclude them from the dataset. Apart from this, all the other informations are complete.","metadata":{}},{"cell_type":"code","source":"df.dropna(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-25T00:23:42.849119Z","iopub.execute_input":"2022-04-25T00:23:42.849501Z","iopub.status.idle":"2022-04-25T00:23:42.85627Z","shell.execute_reply.started":"2022-04-25T00:23:42.849417Z","shell.execute_reply":"2022-04-25T00:23:42.855672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"execution":{"iopub.status.busy":"2022-04-25T00:23:42.857433Z","iopub.execute_input":"2022-04-25T00:23:42.857911Z","iopub.status.idle":"2022-04-25T00:23:42.914457Z","shell.execute_reply.started":"2022-04-25T00:23:42.85784Z","shell.execute_reply":"2022-04-25T00:23:42.91359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Now everything looks fine\ndf.info()","metadata":{"execution":{"iopub.status.busy":"2022-04-25T00:23:42.915986Z","iopub.execute_input":"2022-04-25T00:23:42.916238Z","iopub.status.idle":"2022-04-25T00:23:42.930984Z","shell.execute_reply.started":"2022-04-25T00:23:42.916206Z","shell.execute_reply":"2022-04-25T00:23:42.930272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Population and Sex are not numerical variables, lets convert them to numerical ones in order to \n#apply Multiple Linear Regression using them\nsex_dict = {\"m\": 0, \"f\":1}\ndf[\"numeric_sex\"]=df[\"sex\"].map(sex_dict)\n\npop_dict = {\"Vic\": 0, \"other\": 1}\ndf[\"numeric_pop\"]=df[\"Pop\"].map(pop_dict)","metadata":{"execution":{"iopub.status.busy":"2022-04-25T00:23:42.932059Z","iopub.execute_input":"2022-04-25T00:23:42.932424Z","iopub.status.idle":"2022-04-25T00:23:42.947842Z","shell.execute_reply.started":"2022-04-25T00:23:42.932387Z","shell.execute_reply":"2022-04-25T00:23:42.946926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Now it looks good\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-25T00:23:42.949027Z","iopub.execute_input":"2022-04-25T00:23:42.949275Z","iopub.status.idle":"2022-04-25T00:23:42.978815Z","shell.execute_reply.started":"2022-04-25T00:23:42.949243Z","shell.execute_reply":"2022-04-25T00:23:42.978086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Lets take a look at the name of the columns\ndf.columns","metadata":{"execution":{"iopub.status.busy":"2022-04-25T00:23:42.979796Z","iopub.execute_input":"2022-04-25T00:23:42.980516Z","iopub.status.idle":"2022-04-25T00:23:42.994323Z","shell.execute_reply.started":"2022-04-25T00:23:42.980481Z","shell.execute_reply":"2022-04-25T00:23:42.993676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#We are going to use the other informations to predict, total length.\nX = df[['age', 'hdlngth', 'skullw','taill', 'footlgth', 'earconch', 'eye', 'chest', 'belly', \n        'numeric_sex','numeric_pop']]\ny = df['totlngth']","metadata":{"execution":{"iopub.status.busy":"2022-04-25T00:23:42.995248Z","iopub.execute_input":"2022-04-25T00:23:42.995795Z","iopub.status.idle":"2022-04-25T00:23:43.011153Z","shell.execute_reply.started":"2022-04-25T00:23:42.995764Z","shell.execute_reply":"2022-04-25T00:23:43.009876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2022-04-25T00:23:43.013591Z","iopub.execute_input":"2022-04-25T00:23:43.014046Z","iopub.status.idle":"2022-04-25T00:23:43.077249Z","shell.execute_reply.started":"2022-04-25T00:23:43.014011Z","shell.execute_reply":"2022-04-25T00:23:43.07651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#2 is the number I like the most!\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=2)","metadata":{"execution":{"iopub.status.busy":"2022-04-25T00:23:43.07987Z","iopub.execute_input":"2022-04-25T00:23:43.080282Z","iopub.status.idle":"2022-04-25T00:23:43.08724Z","shell.execute_reply.started":"2022-04-25T00:23:43.080234Z","shell.execute_reply":"2022-04-25T00:23:43.086288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nlm = LinearRegression()\nlm.fit(X_train,y_train)","metadata":{"execution":{"iopub.status.busy":"2022-04-25T00:23:43.088738Z","iopub.execute_input":"2022-04-25T00:23:43.088986Z","iopub.status.idle":"2022-04-25T00:23:43.132756Z","shell.execute_reply.started":"2022-04-25T00:23:43.088955Z","shell.execute_reply":"2022-04-25T00:23:43.132112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#These are the variables and their coefficients in the Multiple Linear Regression\n#The coefficients can be interpreted as the weights of the variables\ndf_coefs = pd.DataFrame(data = {'V':lm.coef_},index=X_train.columns )\ndf_coefs","metadata":{"execution":{"iopub.status.busy":"2022-04-25T00:23:43.133779Z","iopub.execute_input":"2022-04-25T00:23:43.1345Z","iopub.status.idle":"2022-04-25T00:23:43.145281Z","shell.execute_reply.started":"2022-04-25T00:23:43.134424Z","shell.execute_reply":"2022-04-25T00:23:43.144654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#We made reasonable predictions\npredictions = lm.predict(X_test)\nsns.scatterplot(x=y_test,y=predictions)","metadata":{"execution":{"iopub.status.busy":"2022-04-25T00:23:43.146381Z","iopub.execute_input":"2022-04-25T00:23:43.146762Z","iopub.status.idle":"2022-04-25T00:23:43.410908Z","shell.execute_reply.started":"2022-04-25T00:23:43.146725Z","shell.execute_reply":"2022-04-25T00:23:43.409945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#This is the distribuiton of our error\nsns.histplot(y_test-predictions,bins=10)","metadata":{"execution":{"iopub.status.busy":"2022-04-25T00:23:43.412509Z","iopub.execute_input":"2022-04-25T00:23:43.412751Z","iopub.status.idle":"2022-04-25T00:23:43.642277Z","shell.execute_reply.started":"2022-04-25T00:23:43.41272Z","shell.execute_reply":"2022-04-25T00:23:43.641678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#This is the average error, only 2.2cm\nfrom sklearn import metrics\nprint('RMSE:', np.sqrt(metrics.mean_squared_error(y_test,predictions)))","metadata":{"execution":{"iopub.status.busy":"2022-04-25T00:23:43.643335Z","iopub.execute_input":"2022-04-25T00:23:43.643673Z","iopub.status.idle":"2022-04-25T00:23:43.649475Z","shell.execute_reply.started":"2022-04-25T00:23:43.643644Z","shell.execute_reply":"2022-04-25T00:23:43.648612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Lets take a look at the correlation between the variables\nplt.subplots(figsize=(10,10))\nsns.heatmap(df.corr(),annot=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-25T00:23:43.650731Z","iopub.execute_input":"2022-04-25T00:23:43.650951Z","iopub.status.idle":"2022-04-25T00:23:44.97689Z","shell.execute_reply.started":"2022-04-25T00:23:43.650924Z","shell.execute_reply":"2022-04-25T00:23:44.975833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Lets now try to make the prediction using only the variables with the biggest correlations\nX = df[['hdlngth', 'skullw','taill', 'footlgth', 'belly']]\ny = df['totlngth']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=2)\nlm = LinearRegression()\nlm.fit(X_train,y_train)\npredictions = lm.predict(X_test)\nsns.scatterplot(x=y_test,y=predictions)\nprint('RMSE:', np.sqrt(metrics.mean_squared_error(y_test,predictions)))","metadata":{"execution":{"iopub.status.busy":"2022-04-25T00:23:44.9781Z","iopub.execute_input":"2022-04-25T00:23:44.978343Z","iopub.status.idle":"2022-04-25T00:23:45.248435Z","shell.execute_reply.started":"2022-04-25T00:23:44.978311Z","shell.execute_reply":"2022-04-25T00:23:45.247688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#What about using only the tail length?\n#Lets now try to make the prediction using only the variables with the biggest correlations\nX = df[['taill']]\ny = df['totlngth']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=2)\nlm = LinearRegression()\nlm.fit(X_train,y_train)\npredictions = lm.predict(X_test)\nsns.scatterplot(x=y_test,y=predictions)\nprint('RMSE:', np.sqrt(metrics.mean_squared_error(y_test,predictions)))","metadata":{"execution":{"iopub.status.busy":"2022-04-25T00:23:45.249495Z","iopub.execute_input":"2022-04-25T00:23:45.25029Z","iopub.status.idle":"2022-04-25T00:23:45.634679Z","shell.execute_reply.started":"2022-04-25T00:23:45.250242Z","shell.execute_reply":"2022-04-25T00:23:45.63358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}}]}